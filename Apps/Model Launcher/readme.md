# ğŸ§  Pathline â€” Model Picker UI  
**Launch LLMs & Whisper models with zero terminal hassle.**

A Python-based GUI to easily launch local AI models (like GGUF LLMs or Whisper ASR) using a config file or manual selection. No need to type commands or deal with terminal pathsâ€”just point, click, and go.

---

## âœ¨ Features

- ğŸ¯ **One-click launch** for `.gguf` (LLMs) or folder-based models (e.g. Whisper)
- âœ… **Auto compatibility check** (VRAM, RAM, and model size)
- ğŸ—‚ï¸ **Load config.json** to auto-fill paths and settings
- ğŸ” **Start / Stop server** directly from the UI
- ğŸ’¡ **Helpful tooltips** for every field
- ğŸ”§ **Python + CustomTkinter** powered, minimal dependencies

---

## ğŸ“¦ Requirements

- Python 3.8+
- `customtkinter`
- `psutil`

Install with:
```bash
pip install customtkinter psutil
```

---

## ğŸš€ How to Use

1. Run the UI:

```bash
python model_picker_ui.py
```

2. Select:
   - **Model Type**: `file` for `.gguf` LLMs, `folder` for Whisper or similar
   - **Model Path**: Use the browse button or load a `config.json`

3. âœ… See if your system can handle the model (VRAM & RAM check)

4. Click **Start Server** to launch  
   Click **Stop Server** to kill the process

---

## ğŸ—‚ï¸ Config Example (`config.json`)

```json
{
  "model_path": "D:/Models/qwen1_5-4b-chat.gguf",
  "model_type": "file",
  "server_exe": "D:/Apps/llama-server.exe",
  "port": 8085
}
```

---

## ğŸ“ File Overview

- `model_picker_ui.py` â€” The GUI interface
- `run_model_server.py` â€” The terminal-based fallback CLI runner
- `config.json` â€” Example config file
- `start_model_picker.bat` â€” Windows launcher (optional)

---

## ğŸ¤ License

MIT License â€” free to use and modify. Credit appreciated.

---

## ğŸ’¬ Community & Support

Join our Discord: [your Discord invite here]  
Follow for updates: [@KalponicStudio](https://twitter.com/kalponicstudio)
